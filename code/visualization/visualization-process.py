import pandas
from sqlalchemy import create_engine
from bokeh.plotting import output_file, show
from bokeh.io import show
from bokeh.models import ColumnDataSource, DataTable, TableColumn
import dbconfig
from datetime import timedelta, datetime
from prefect import task, Flow
from prefect.schedules import IntervalSchedule
from prefect.executors import LocalDaskExecutor

@task(max_retries=3, retry_delay=timedelta(seconds=1))
def getMLResult(status):
    ''''
    Get table generated by the ML process from the database
    '''
    # Open connection to the database
    alchemyEngine = create_engine(f'postgresql+psycopg2://{dbconfig.USER}:{dbconfig.PASSWORD}@{dbconfig.HOST}/{dbconfig.DBNAME}', pool_recycle=3600);
    connection = alchemyEngine.connect();
    
    # Get temperature_level table
    sql = """select * from temperature_level ;"""
    data = pandas.read_sql_query(sql,con=connection)

    # Close database connection
    connection.close()

    # Configure table to visualize
    source = ColumnDataSource(data)
    columns = [
            TableColumn(field="region", title="Region"),
            TableColumn(field="country", title="Country"),
            TableColumn(field="city", title="City"),
            TableColumn(field="quarter", title="Quarter"),
            TableColumn(field="avgtemp", title="Temperature"),
            TableColumn(field="templevel", title="Temperature Level"),
        ]
    data_table = DataTable(source=source, columns=columns, width=800, height=800)

    # Output file with results
    output_file("pages/mlresult.html")
    show(data_table)

    return status

@task(max_retries=3, retry_delay=timedelta(seconds=1))
def getETLResult(status):
    ''''
    Get table generated by the ETL process from the database
    '''
    # Open connection to the database
    alchemyEngine = create_engine(f'postgresql+psycopg2://{dbconfig.USER}:{dbconfig.PASSWORD}@{dbconfig.HOST}/{dbconfig.DBNAME}', pool_recycle=3600);
    connection = alchemyEngine.connect();
    
    # Get temperatures table
    sql = "select region, country, city, quarter, cast(date as text), avgtemp from temperatures;"
    data = pandas.read_sql_query(sql,con=connection)

    # Close database connection
    connection.close()
    
    # Configure table to visualize
    source = ColumnDataSource(data)
    columns = [
            TableColumn(field="region", title="Region"),
            TableColumn(field="country", title="Country"),
            TableColumn(field="city", title="City"),
            TableColumn(field="quarter", title="Quarter"),
            TableColumn(field="date", title="Date"),
            TableColumn(field="avgtemp", title="Temperature"),
        ]
    data_table = DataTable(source=source, columns=columns, width=800, height=800)

    # Output file with results
    output_file("pages/etlresult.html")
    show(data_table)

    return status

@task(max_retries=3, retry_delay=timedelta(seconds=1))
def getStatus():
    ''''
    Get table generated with status information from the database
    '''
    # Open connection to the database
    alchemyEngine = create_engine(f'postgresql+psycopg2://{dbconfig.USER}:{dbconfig.PASSWORD}@{dbconfig.HOST}/{dbconfig.DBNAME}', pool_recycle=3600);
    connection = alchemyEngine.connect();
    
    # Get status table
    sql = "select id, status, message, cast(timestamp as text), cast(lastloaded as text) from status;"
    data = pandas.read_sql_query(sql,con=connection)

    # Close database connection
    connection.close()

    # Configure table to visualize
    source = ColumnDataSource(data)
    columns = [
            TableColumn(field="id", title="ID"),
            TableColumn(field="status", title="Status"),
            TableColumn(field="message", title="Message"),
            TableColumn(field="timestamp", title="Timestamp"),
            TableColumn(field="lastloaded", title="Last Date Loaded"),
        ]
    data_table = DataTable(source=source, columns=columns, width=800, height=800)

    # Output file with results
    output_file("pages/status.html")
    show(data_table)

    return "Done!"

def main():
    ''''
    Get data from the database and output to html pages to be accessed via Nginx
    '''
    # Set Prefect scheduler to run every 2 minutes
    schedule = IntervalSchedule(
        start_date=datetime.utcnow() + timedelta(seconds=1),
        interval=timedelta(minutes=2)
    )

    # Configure Prefect flow
    with Flow("visualization", schedule=schedule) as flow:
        result = getStatus()
        result = getETLResult(result)
        result = getMLResult(result)
        print(result)

    # Execute ETL flow
    flow.run(executor=LocalDaskExecutor())

if __name__ == "__main__":
    main()